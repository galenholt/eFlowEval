---
title: "Lippia strictures"
author: "Galen Holt"
format: html
editor: visual
---

## Notebook to run the lippia strictures across the basin

### Setup

```{r}
library(here)
library(tidyverse)
library(sf)
library(stars)
library(foreach)
library(doFuture)
library(doRNG)
```

First, set directories and read-in function

```{r}
source('directorySet.R')
source(file.path('Scripts', 'Strictures', 'lippia.R'))
source(file.path('Scripts', 'Strictures', 'vegCatchmentAggregate.R'))


registerDoFuture()

plan(multisession) # I *think* sequential allows debug?
```

### Check what needs to happen

I don't think we need to chunk. Not sure I need both summaryFun and Varname, so making them the same. It bugs me that I can't just use `makeSHfails` with `nchunks = 1`, but that still sets up the `chunked/CATCHMENTNAME/file` structure. I'm sure I can fix that, but not now.

```{r}
# I've modified makeSHfails to give me a list
runlist <- makeSHfailsNoChunk(outerDir = file.path(datOut, 'Strictures'),
            summaryFuns = 'lippia',
            varName = 'lippia_strictures',
            # nchunks = 1,
            lengthOrChunk = c('short', 'long'), # , 'long', 'chunk'
            runImmediate = FALSE,
            forceAllCatchments = TRUE,
            returnForR = TRUE,
            produce_sh = FALSE)

```

```{r}
runlist
```

## Pre-check the data

I should integrate this into the function, but this is easier to look at

```{r}
check_surv <- test_anae_agg(catchments = 'all', datDir = datOut, variableDir = 'Inundationprocessed', summaryFun = 'lippiaAdultSurvive')

```

If there are sets of polys that fail the matching step, they can't be multiplied for strictures, so we need to fail and deal with that.

```{r}
check_temp <- test_anae_agg(catchments = 'all', datDir = datOut, variableDir = 'Tempprocessed', summaryFun = 'weightedMean')

```

There are some warnings that we're OK with- failing duplicate check on IDs and but they pass on the geometry.

```{r}

surv_fail <- check_surv %>% 
  filter(passfail != 'pass' & !grepl('Assigning based on position', passfail))

temp_fail <- check_temp %>% 
  filter(passfail != 'pass' & !grepl('Assigning based on position', passfail))

if (nrow(surv_fail) > 0) {
  print(surv_fail)
}

if (nrow(temp_fail) > 0) {
  print(temp_fail)
}

if (nrow(surv_fail)  | nrow(temp_fail) > 0) {stop("The stars aren't matching, so can't be used for stricture multiplication. Sort that out.")}
```

## Set up the runs

run the loops over catchments. No chunks here, I don't think.

*how would I do this with batchtools? I think just ask for length(runlist) cpus (or tasks, if using the batchtools template) without worrying about nodes.*

For ref, longest one takes about 3.5 minutes, took about 10 mins to run locally with `plan(multisession)` .

```{r}
#| warning: false
# Run over the catchments
alltimes <- foreach(w = runlist, 
                    .combine = rbind, 
                    .errorhandling = 'remove') %dofuture% {
            lippiatime <- lippiastricts(catchment = w, 
                                   savefile = TRUE, returnR = FALSE)
            
            lippiatime
          }
```

### Timings

The timings are saved in alltimes

```{r}
alltimes
```

## Aggregate the data to the catchment scale

```{r}
veg_catch_agg(datOut = datOut, summaryFuns = 'lippia')
```
